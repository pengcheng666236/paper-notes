# Defect Knowledge Graph Construction and application in Multi-Cloud IoT
## 黑话

| Symbol Representation |                                                              |
| --------------------- | ------------------------------------------------------------ |
| Q & A                 | question and answer                                          |
| ES                    | elastic search                                               |
| OSS                   | Object Storage Service                                       |
| MOM                   | Message Oriented Middleware                                  |
| ISC                   | Internet Service Customer                                    |
| S6000                 | a network equipment                                          |
| r(X0, Xn)             | the relationship between X0 and Xn                           |
| G                     | the knowledge graph                                          |
| Pd                    | the representation of training data                          |
| q                     | the question to be queried                                   |
| a                     | the inference result                                         |
| P_{w}                 | the probability of an answer conditioned (有条件的回答)defined by Reasoning Evaluator |
| p_{0}                 | the prior probability of an answer conditioned defined by Rule Miner |
| R                     | the representation of rule set                               |
| **E**                 | the maximum likelihood estimation                            |
| W_{rule}              | the weight of the rule                                       |
| score_{w}             | the score of candidate answer in set A                       |
| exp                   | the representation of exponential function in softmax        |
| log                   | the representation of log function                           |
| H                     | the score of rules’ quality                                  |
| t                     | the representation of tail entity of knowledge triple        |
| A                     | the set of candidate answers                                 |
| MD                    | the representation of polynomial distribution                |
| N                     | the sampling number parameter in polynomial distribution     |
| GRU                   | the representation of Gate Recurrent Unit                    |
| f                     | the representation of explicit function mapping used in GRU network |
| K                     | the number of high-quality rules to output                   |
| max_{O}               | the representation of maximizing the loglikelihood of the ruleset |

## 1.引言

### 1.1国家电网多云结构的设计背景

> 1.IoT设备广泛流行，随之产生了大量的计算密集型应用。而因为软硬件设备的限制，难以实现本地的数据处理。
>
> 2.单独云服务提供商提供的服务种类是有限的，而且会出现服务资源锁定的问题。
>
> - Service resource locking是一种保护Azure资源的机制，可以将Azure订阅、资源组或资源锁定，以防止用户意外删除或修改它们。锁定会覆盖任何用户权限。可以设置防止删除或修改的锁定。在门户中，这些锁定称为删除和只读。锁定的原理是在资源、资源组或订阅的设置中选择锁定，然后添加锁定。如果要在父级别创建锁定，请选择父级别。当前选择的资源从父级继承锁定。例如，可以锁定资源组以将锁定应用于其所有资源。在应用锁定时，需要提供资源的名称和作用域。可以通过更新蓝图分配来设置不同的锁定模式。锁定的作用是防止多个用户在同一时间试图使用同一个资源，以保护数据在多处理环境中的安全性。锁定可以防止意外或未经授权的删除、修改或移动资源。如果删除锁定，则Azure将允许用户删除或修改资源。

### 1.2本系统介绍

> 鉴于电网产生的大量基本设备信息，以及对漏洞处理的实时性要求，提出一种基于国家电网设备架构的，在多云存储上的，应对大数据生成的解决方案，该模型
>
> - 遵守国家电网SG-EA技术架构
> - 使用融合算法进行本体设计
> - 基于预先设置的逻辑规则，设计图谱推理方法GRULR
> - 可以独立部署在不同的云服务上，提高系统的鲁棒性和安全性，不影响一致性
>
> GRULR，也就是图谱reasoning部分分为Reasoning Evaluator和Rule Miner，可以部署在不同云服务器上，，从而对电网的多云服务架构进行适配。
>
> 同时，根据在不同云上共享高质量的规则，该模型可以避免供应商垄断封锁，实现迭代更新。
>
> 最后，得出结论：GRULR在大规模图谱上效果良好，可以高效完成漏洞图谱的完善功能。

### 1.3本系统模块介绍

> 本体设计，知识抽取，知识融合，知识推理。
>
> 图谱融合了上用的系统设备的数据库，专家知识库，漏洞数据日志，漏洞分析报告，设计标准，规则等等，能够提供智能的，个性化的能源设备漏洞知识服务。
>
> 针对用户输入，提供智能的，多轮问答服务，主要面对常见的漏洞业务场景，包括
>
> - 设备缺陷案例
> - 缺陷分类与判断
> - 基站、设备网格的拓扑信息
> - 缺陷处理程序等

### 1.4图谱构建

> 使用NLP进行文本处理，高速构建图谱
>
> 使用全自动化的图谱构建方法
>
> ![image-20230512095605286](https://cdn.jsdelivr.net/gh/pengcheng666236/picGo@master/20230512095752.png)

### 1.5图谱推理

面向知识图谱的知识推理大致可以分为三类：

（1）基于逻辑的推理方式：通过一阶谓词逻辑、描述逻辑等，利用规则推理出新的实体关系

（2）基于统计的方法：通过机器学习从知识图谱中统计出规律

（3）基于图的推理方法：path ranking 算法和基于神经网络的方法

![img](https://cdn.jsdelivr.net/gh/pengcheng666236/picGo@master/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RpYW55dWhhbmcxMjM=,size_16,color_FFFFFF,t_70.png)

#### 1.5.1基于逻辑规则的图谱推理方法GRULR

> 使用最大似然估计，对推理模块的Gate Recursive Unit的网络参数进行更新。
>
> - 给定一组观测数据，定义一个似然函数（用于计算观测数据的概率）。
> - 然后，使用最大化似然函数的方法来估计模型参数：找到一组参数值，使得给定数据集的似然函数最大化。最大似然估计的计算方法可以通过求导数/偏导数为零的方式来实现。
> - 最大似然估计和贝叶斯估计是两种常用的参数估计方法。
>   - 最大似然估计是一种频率学派的方法，它假设参数是固定的但未知的，并通过最大化似然函数来估计参数。似然函数是给定数据集的条件下，参数的概率密度函数。最大似然估计的结果是一个**点估计**，即一个确定的参数值。
>   - 贝叶斯估计是一种贝叶斯学派的方法，它假设参数是随机的，并使用贝叶斯公式来计算参数的后验分布。将先验概率和似然函数结合起来，计算后验概率分布，从而得到参数的估计值。与最大似然估计不同，贝叶斯估计不仅考虑了样本数据，还考虑了先验知识。在贝叶斯估计中，先验概率可以是任意分布，而后验概率则是先验概率和似然函数的乘积，再除以归一化常数。贝叶斯估计的优点是可以利用先验知识来提高估计的准确性，缺点是需要选择合适的先验分布，并且计算复杂度较高。**贝叶斯估计的结果是一个分布，即参数的后验分布**。贝叶斯估计**使用先验知识来指导参数估计**，因此在数据量较小或噪声较大时，贝叶斯估计通常比最大似然估计更稳健。
>
> 使用后验概率，来辨别一条规则是否是高质量的
>
> 使用EM最大期望（Expectation Maximum）技术进行迭代训练
>
> - EM算法的基本思想是通过迭代的方式，**先对隐变量进行估计，然后再对模型参数进行估计**，不断重复这个过程，直到收敛为止。EM算法的迭代过程包括两个步骤：E步骤和M步骤。
>
>   - 在E步骤中，根据当前的参数估计值，计算隐变量的后验概率分布；
>
>   - 在M步骤中，根据当前的隐变量后验概率分布，计算模型参数的极大似然估计值。
>
>     
>
>     EM算法的优点是可以处理存在隐变量的概率模型，缺点是需要选择合适的初始值，并且可能会陷入局部最优解。
>
> - 假设我们有一组数据，其中一些数据是有缺失的，我们希望通过这些数据来估计模型的参数。例如，我们有一组学生的考试成绩数据，但是有些学生的成绩是缺失的。我们可以使用EM算法来估计这些学生的成绩，并通过这些数据来估计模型的参数。在E步骤中，我们计算缺失数据的后验概率分布，即给定已知数据和当前参数估计值的情况下，缺失数据的概率分布。在M步骤中，我们计算模型参数的极大似然估计值，即使得似然函数最大化的参数值。通过不断迭代E步骤和M步骤，直到收敛为止，我们就可以得到模型的参数估计值和缺失数据的估计值。

#### 1.5.2传统方法

知识图谱推理的传统方法，大多是列举图上的关系路径作为候选，然后根据逻辑规则，学习每个候选路径的权重，最后根据算法进行评估规则质量。

> - path sorting 算法，主要思想是根据每个节点的入度和出度来计算其权重，并根据权重对节点进行排序。
>
>   - 特征抽取（生成并选择路径，生成路径对应的特征集合）
>    方法：随机游走，广度优先搜索，深度优先搜索
> 
>   2. 特征计算（计算每个训练样例的特征值）
>  方法：随机游走概率，布尔值（出现/不出现），出现频次/概率
>   3. 分类器训练（根据训练样例，为每个目标关系训练一个分类器）
>   方法：单任务学习（为每个关系单独训练二分类器）；多任务学习（不同关系联合学习）
>   - 对于图谱中的实体，首先选择一对具有某种关系的实体entitles，然后在库中所有的subject随机行走，能到达object的路径算成功,例如夫妻关系可以由共同的孩子推断
>     $$
>     X->Y<-Z
>     $$
>     或者曾祖父可以由两层父亲关系推断
>     $$
>     X->Y->Z
>     $$
>     路径的质量由支持度和准确度确定。
> 
>     - 如果一条路径的支持度很高，但是准确度很低，说明该路径虽然出现的频率很高，但是其描述的模型并不准确，不能够很好地反映实际情况。
>    - 反之，如果一条路径的支持度很低，但是准确度很高，说明该路径虽然不常见，但是其描述的模型非常准确，可以作为一条重要的路径进行挖掘，进而根据每条正确路径推导出一条规则rule。
>     - 一对实体可能经过多条路径，因此通过一个二值分类器来结合表示，每条路径为分类器提供一个特征的值。
> 
>     | Input : knowledge  graph,the source node s and the target node t. |
>    | :----------------------------------------------------------- |
>     | **Output**: **one or more  relation paths from s to t ranked by importance.** |
>     | 1:  Initialize an array R of size n to all  zeros.           |
>     | 2:  Set R[s] = 1.                                            |
>     | 3:  Topologically sort the vertices of  G.  //根据依赖关系进行排序 |
>     | 4:  for each vertex v in the order  given by the sort do     |
>     | 5:        for each incoming edge (u,v) do                    |
>     | 6:               Set R[v] = R[v] + R[u].                     |
>     | 7:        end for                                            |
>     | 8:  end for                                                  |
>     | 9:  return R[t].                                             |
> 
> - Pro PPR
>
>   - PRO（Personalized Random Walk with Restart Objective）是一种基于随机游走的**有监督**图节点分类算法。它**通过在图中随机游走来计算每个节点的特征向量，并使用这些向量来训练分类器**。PRO算法的主要优点是可以处理大规模图，并且具有较高的准确性。
>
>   - PPR（Personalized PageRank）也是一种基于随机游走的**有监督**图节点分类算法。它**通过在图中随机游走来计算每个节点的PageRank值，并使用这些值来训练分类器**。PPR算法的主要优点是可以处理大规模图，并且具有较高的准确性。
>
>     两种算法的不同之处在于，PRO算法计算节点的特征向量，而PPR算法计算节点的PageRank值。另外，PRO算法可以使用多个起点进行随机游走，而PPR算法只能使用一个起点。
>
>     总的来说，PRO算法和PPR算法都是基于随机游走的图节点分类算法，它们可以处理大规模图，并且具有较高的准确性。选择哪种算法取决于具体的应用场景和数据特征。
>
>   - PROPPR是一种基于随机游走的图算法，用于进行有监督的预测任务，如图节点分类和链接预测。它是PRO和PPR算法的结合体，结合了两者的优点。
>
>     PROPPR使用随机游走来计算每个节点的特征向量，并使用这些向量来训练分类器。与PRO算法相似，PROPPR使用多个起点进行随机游走，以提高算法的效率和准确性。与PPR算法相似，PROPPR使用随机游走计算节点的PageRank值，并使用这些值来训练分类器。此外，PROPPR还使用了一些新的技术，如梯度下降和矩阵分解，以优化算法的性能。
>
>     PROPPR的主要优点是可以处理大规模图，并且具有较高的准确性和效率。它已被广泛用于许多领域，如自然语言处理、社交网络分析和推荐系统等。
>
> - Markov logic network
>
>   - 在自然语言处理领域，马尔可夫逻辑网可以用于语义解析和问答系统。通过将自然语言句子转化为逻辑公式，并使用马尔可夫逻辑网进行推理，可以实现对自然语言的理解和回答问题的能力。
>
>   - ![img](C:\Users\8208191402\Desktop\笔记\图片\20180416145135201.jpeg)
>
>   - | 具体流程                                                     |
>    | ------------------------------------------------------------ |
>     | 定义实体：从知识库中确定需要建立关系的实体，例如人、物、事件等。 |
>     | 定义状态：对每个实体定义状态，例如人可以有“健康”、“生病”等状态。 |
>     | 定义关系：确定实体之间的关系，例如人可以与医生、疾病等实体建立关系。 |
>     | 建立状态转移矩阵：根据实体的状态和关系，建立状态转移矩阵，表示实体之间状态的转移概率。 |
>     | 建立观测矩阵：建立观测矩阵，表示对实体状态的观测概率，例如对人的健康状态进行观测，观测结果可以是“健康”、“生病”等。 |
>     | 建立初始概率向量：确定每个实体的初始状态概率向量，例如人的初始状态可以是“健康”和“生病”的概率分别为0.8和0.2。 |
>     | 定义问题：确定需要解决的问题，例如预测人的健康状态。         |
>     | 运用算法：使用马尔科夫逻辑网算法对模型**进行推理**，得出对问题的答案，例如预测某个人的健康状态为“生病”。 |
> 
>   - 逻辑推理的过程：
>
>     - 确定问题：确定需要解决的问题，例如预测某个人的健康状态。
>    - 定义观测值：确定已知的观测值，例如已知某个人有发热症状。
>     - 计算后验概率：根据观测值和模型，计算后验概率，即给定观测值的情况下，某个实体处于某个状态的概率。
>     - 进行推理：根据后验概率，进行推理，得出对问题的答案，例如预测某个人的健康状态为“生病”。
> 
>   - 优势
>
>     - 当规则及其权重已知时：推断知识图谱中任意未知事实成立的概率（马尔可夫随机场的推断问题）**证据变量为知识图谱中的已知事实，问题变量为未知事实**
>    - 当规则已知但其权重未知时：自动学习每条规则的权重（马尔可夫随机场的参数学习）
>     - 当规则及其权重均未知时：自动学习规则及其权重（马尔可夫随机场的结构学习），属于上述归纳推理的范畴

#### 1.5.3使用神经网络的方法

基于神经网络的推理方法主要有三种：基于语义的推理、基于结构的推理辅助存储的推理

##### 一：基于语义的推理

基于语义的推理建立在挖掘和利用语义信息的基础上，例如实体和关系的名称、描述以及上下文信息等。

1.NTN 模型，关系张量表示和切片

利用双线性张量层代替传统的标准线性神经网络。**将实体表示为向量来获取实体信息，用参数表示关系，将关系表示为三阶张量并且关联两个实体。**将关系表示为张量的好处是，一个关系有多个切片，每个切片都对应一种不同的语义，这样可以更好地建模该关系下不同实体之间的不同语义。

双线性张量层是一种神经网络层，它采用双线性插值的方式将两个输入的特征图进行融合。在计算机视觉任务中，这种层通常用于将两个不同的特征图进行融合，以提高模型的性能。具体来说，双线性张量层接收两个输入张量，分别为X1和X*2，它们的形状分别为(B*,*C*1,*H*1,*W*1)和(*B*,*C*2,*H*2,*W*2)，其中B*表示批量大小，C*1和C*2分别表示两个特征图的通道数，H*1和W*1分别表示第一个特征图的高度和宽度，H*2和W*2分别表示第二个特征图的高度和宽度。

双线性张量层将输入张量进行展平，然后使用双线性插值的方式计算它们的外积，得到一个形状为(*B*,*C*1×*C*2,*H*1×*H*2)的张量。最后，双线性张量层将其重新形状为(*B*,*C*1×*C*2,*H*1,*W*1)，并将其作为输出返回。

双线性张量层的优点在于它能够捕捉两个特征图之间的相关性，从而提高模型的性能。在计算机视觉任务中，它通常用于将不同层次的特征图进行融合，以获得更丰富的特征表示。

 ![](C:\Users\8208191402\Desktop\笔记\图片\watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RpYW55dWhhbmcxMjM=,size_16,color_FFFFFF,t_70-16838693998155.png)

![](C:\Users\8208191402\Desktop\笔记\图片\20191201214300801.png)

其中 f=tanh 是一个标准非线性函数，![](C:\Users\8208191402\Desktop\笔记\图片\20191201215110543.png)是 一个张量， ![](C:\Users\8208191402\Desktop\笔记\图片\20191201215135546.png) 是双线性张量积，其结果为 h∈Rk, 每个 hi 代表一个张量切片![](C:\Users\8208191402\Desktop\笔记\图片\20191201215214990.png)，关系 R 的其他 参数参照标准神经网络：![](C:\Users\8208191402\Desktop\笔记\图片\2019120121524249.png) 。 

g(e1,R,e2) 函数得分越高，说明实体 e1 和 e2 之间处于关 系 R 的可能性越高。

2.DKRL，基于描述的模型

大部分知识表示模型只会关注实体和关系名称的嵌入，但是大多数的知识图谱中还存在着对实体的描述，这些描述丰富了语义信息，但是却没有得到足够重视。DKLR 就是一种基于描述的模型，通过对描述内容的学习，不仅可以获取三元组的结构学习，还可以获得实体描述中的关键词和隐藏在语序中的文本信息。

![](C:\Users\8208191402\Desktop\笔记\图片\watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RpYW55dWhhbmcxMjM=,size_16,color_FFFFFF,t_70-16838693998166.png)

![](C:\Users\8208191402\Desktop\笔记\图片\watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RpYW55dWhhbmcxMjM=,size_16,color_FFFFFF,t_70-16838693998177.png)

![](C:\Users\8208191402\Desktop\笔记\图片\watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RpYW55dWhhbmcxMjM=,size_16,color_FFFFFF,t_70-16838693998178.png)

3.ProjE 模型

随着知识库存储量的不断增大，知识推理模型特征 空间日益复杂，参数规模也随之不断增长。Shi 等人 [17] 通过简化底层模型体系结构，提出一种效果更好而参数 规模更小的投影嵌入模型（Embedding Projection，ProjE）， 其主要方法是将实体预测视为多候选项排名问题，取其 中排名得分最高的候选项为实体预测结果

![](C:\Users\8208191402\Desktop\笔记\图片\watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RpYW55dWhhbmcxMjM=,size_16,color_FFFFFF,t_70-16838693998179.png)

该方法的大致思路就是将已知信息预先组合在一起生成一个目标向量，然后每个候选对象的对应的向量与该目标向量计算相似度。排名高的就作为预测结果。上述的 D 矩阵为权重矩阵（实体和关系）。

4.MT-KGNN 模型

知识图谱中还存在这丰富的属性信息，所以构建了多任务神经网络体系结构，学习实体、关系、属性的表示。涉及两个神经网络，关系网络和属性网络。

由于头实体与尾实体被认为是反对称的，所以把属性网络分为两部分，利用左属性网 AttrNet（left）获取头实体及其属 性，利用右属性网 AttrNet（right）获取尾实体及其属性。 

![](C:\Users\8208191402\Desktop\笔记\图片\watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RpYW55dWhhbmcxMjM=,size_16,color_FFFFFF,t_70-168386939981710.png)

##### 二：基于结构的推理

基于三元组内部或者三元组之间的结构联系进行推理，一般有三种：基于相邻实体的推理模型、基于多条关系的推理模型、基于组合路径的推理模型

1. 基于相邻实体的推理模型 --  R-GCN

R-GCN 相当于一个自编码器，包括一个编码器，一个解码器

编码器是一个 R-GCN 网，将目标实体与知识图谱 中的邻居实体进行卷积学习，输入当前实体的相邻关系 信息，包括关系类型、关系的方向以及实体自循环的信 息，然后输出目标实体的隐性特征向量表示并将其输入 解码器

![](C:\Users\8208191402\Desktop\笔记\图片\watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RpYW55dWhhbmcxMjM=,size_16,color_FFFFFF,t_70-168386939981811.png)

解码器是一个张量分解模型，使用 DistMult[24] 作为 得分函数，计算头实体向量的转置、关系特定的对角矩 阵和尾实体向量的乘积，由此引入关系向量的建模，标 记待预测关系。 

2. 基于多跳关系的推理模型

很多三元组之间具有链接关系（即有的三元组的尾是其他三元组的头），这样多个三元组即可构成一条路径

基于多跳关系的推理模型就是使用递归神经网络将路径上的关系的语义组合起来。

![](C:\Users\8208191402\Desktop\笔记\图片\watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RpYW55dWhhbmcxMjM=,size_16,color_FFFFFF,t_70-168386939981812.png)

3. 基于组合路径的推理模型

和基于多跳关系的推理模型差不多，不过两个实体之间的路径可能不止一条，基于组合路径的推理模型就是利用 attention 把所有路径都考虑进去。

##### 三. 基于辅助存储的推理

就是模仿人脑对知识的存储能力，通过设计共享记忆组件来存储信息。

1.IRN 模型

![](C:\Users\8208191402\Desktop\笔记\图片\watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RpYW55dWhhbmcxMjM=,size_16,color_FFFFFF,t_70-168386939981813.png)

2.DNC 模型

除了存储信息，人脑还可以对知识进行读写，所以该模型设计了一个共享矩阵，该矩阵可以选择性的进行读写操作。

问题：搜索空间是指数级增长的

#### 使用强化学习的方法

> 把学习逻辑规则问题转化为持续性的决策问题，构建强化学习模型。
>
> 具体来说，将图谱中的每个节点看作一个状态，将节点之间的逻辑规则看作动作，将节点之间的关系看作奖励。在这个框架中，智能体需要不断地从当前状态中选择一个动作，并根据所获得的奖励来更新自己的策略。智能体的目标是最大化累积奖励，即获得最大的图谱逻辑规则得分。
>
> |                    |      |
> | ------------------ | ---- |
> | 图谱中的每个节点   | 状态 |
> | 节点之间的逻辑规则 | 动作 |
> | 节点之间的关系     | 奖励 |
>
> - 在图谱中，节点之间的逻辑关系可以看作是动作。节点之间的逻辑关系通常包括推理、蕴含、否定等操作，这些操作可以看作是对当前状态的改变，也就是动作。例如，如果节点A和节点B之间存在推理关系，那么可以将这个推理关系看作是从节点A到节点B的一个动作。
> - 如果两个节点之间的逻辑规则能够正确地推导出一个新的节点，则给予正奖励，否则给予负奖励。
>
> - 智能体需要学习一个策略，以在每个状态下选择最优的动作。可以通过深度强化学习等方法来学习策略。
>
> 缺陷：动作所包含的空间太大，导致收益低。
>
> - 状态空间过大：知识推理涉及到的状态空间通常非常大，这意味着强化学习需要花费很长时间来探索状态空间。如果探索不足，那么强化学习的性能就会受到限制。

## 2.相关工作

> 知识融合：目前的知识融合主要分为实体融合与数据融合，本图谱结合了国家电网IoT云环境的特点和需求，用于分配带宽和计算资源，构建领域图谱。
>
> 知识推理：
>
> - 传统方法通过对候选规则进行权重学习，打分排序；
> - 目前方法多是基于神经网络，将输入数据的特征映射，通过非线性变换到高维空间，自动化学习特征表示（特征矩阵）。
> - 我们的方法结合神经网络，把规则和权重分开到Rule Miner和Reasoning Evaluator中。
>
> 张量拆解，把实体和关系在高维的表示拆成多个低维向量，对实体和关系的embedding向量进行学习。

## 3.图谱构建

![image-20230512144910811](C:\Users\8208191402\Desktop\笔记\图片\image-20230512144910811.png)

> data layer：基于多云平台的不同数据存储方案，整合多个数据源。包括图数据库，第三方关系数据库，缓存数据库（redis），对象存储服务等（OSS：将数据以对象的形式存储，每个对象包含数据、元数据和唯一的标识符，可以通过标识符在任何地方进行访问和检索。对象存储服务具有高可用性、高可扩展性、低成本等优点，适用于存储海量数据、大文件、多媒体等各种类型的数据）。
>
> support layer：对构建知识图谱方法的具体实现，包括
>
> - 知识计算（处理和应用知识的手段，重在对表示方式进行统一，使能够用于自动化分析决策）、
> - 实体对齐（将不同知识图谱中的实体进行匹配和对应，从而将它们连接起来）、
> - 知识建模（把知识和经验转化为计算机程序可处理的形式，重在表示，例如规则，本体）、
> - 知识纠错
>
> service layer：提供图分析模型，系统运行日志、查询服务接口、规则设置接口、文档管理接口
>
> application layer：外部服务接口，包括知识问答，误差分析，智能漏洞检测

技术栈

![image-20230512150029516](C:\Users\8208191402\Desktop\笔记\图片\image-20230512150029516.png)

### 3.1本体设计

> 结合自底向上的实体归纳法和自顶向下的概念细化法，首先使用专家知识进行自顶向下构建图谱，然后使用NLP工具进行图谱的更新操作。
>
> 本体设计以设备的漏洞本身为核心，结合现有的设备漏洞事务和模型，构建二极本体中心，将涉及的属性分裂成更多本体。
>
> ![image-20230512150718888](C:\Users\8208191402\Desktop\笔记\图片\image-20230512150718888.png)

### 3.2知识抽取，知识融合

构建过程

![image-20230512150904842](https://cdn.jsdelivr.net/gh/pengcheng666236/picGo@master/image-20230512150904842.png)

预处理

> 对获取的数据进行数据清洗和数据标记。
>
> 数据清洗：去除多余数据，填充缺失字段，删除错误数据
>
> 数据标记（data annotation）：让数据转化为有用的格式，便于算法处理。
>
> - 根据数据类型，可以分为图片，音频，视频等等
> - 根据数据来源，可以分为设备缺陷原始数据、标准规范、系统指南、缺陷报告等等

知识抽取

> 对于设备映射对象、设备事件定义和设备历史信息等信息，可以使用
>
> - 信息提取（编程、NLP工具）、
> - D2R conversion，将关系型数据库（RDB）中的数据转化为RDF语言表示的知识图谱的过程、
> - graph mapping，将多个子图映射到同一个模型中

知识融合

> 包括data pattern layer (concept, the relationship between concepts and attributes of concept) 和
> device data layer。
>
> 知识检索（retrieval）或知识推理主要用于图谱完善和对KG的性能检查，即使用现有的事实或关系
>
> 推断新的事实或关系，主要包括图挖掘计算、本体推理等，和基于规则的推理。
>
> 图挖掘计算：对图中的点、边。模式进行分析，挖掘有效信息
>
> 常见的图挖掘计算算法包括：
>
> 1. 社区检测算法：用于识别社交网络中的社区结构，例如基于模块度的算法、谱聚类算法等。
> 2. 节点分类算法：用于对图中的节点进行分类（<vector,tag>），例如基于随机游走的算法、图卷积神经网络算法等。
> 3. 链路预测算法：用于预测节点之间的边，例如基于相似性的算法、基于随机游走的算法等。
> 4. 子图挖掘算法：用于从大型图中发现有用的子图模式，例如频繁子图挖掘算法、图模式挖掘算法等。
>
> 本体推理包含了基于规则的推理方法。
>
> 基于规则的推理，就是将已知的规则应用到本体中的**实例**上，从而得出新的结论和知识的过程。具体而言，需要定义规则库，规则库中包含了一系列的规则，每个规则由一个前提和一个结论组成。当推理机发现某个实例满足规则的前提时，就会应用该规则，从而得出新的结论和知识。

## 4.图谱推理

>基于概率的形式化知识图谱推理，用于处理多云平台架构下的数据多样性，追求跨平台的统一数据表示。
>
>- 概率推理（ probabilistic reasoning）和逻辑推理（logical reasoning）是两种不同的知识图精化方法。逻辑推理基于形式逻辑，用于验证图中语句的一致性，并删除不一致的语句。而概率推理基于概率论，用于推断遗漏的知识和识别图中的错误信息。
>- 概率推理在处理**不完整或不确定的信息**时特别有用。虽然逻辑推理提供了**可解释**的建议，但概率推理可以通过探索知识图中的相互联系来揭示**新的见解**。然而，概率推理在计算上可能很复杂，并且对于大型知识图可能不可扩展。
>
>关键在于，对跨平台的高质量规则进行更新。

### 4.1规则表示和概率模型

> 图谱规则使用一阶联合逻辑算子进行表示，既可以加快对anti rules和reverse rules的计算速度,还可以展示图谱的结构/推理路径。
> $$
> \forall\{{X_i}\}_{i=0}^{n}r(X_0,X_n) \leftarrow r(X_0,X_1)\and r(X_1,X_2)...\and r(X_{n-1},X_n)
> $$
> 对训练数据统一表示为
> $$
> P_d(G,q,a)\\
> G=set\quad of \quad triples<h,r,t>
> $$
> 使用的概率模型和RNNLogic中的模型一致：
> $$
> P_{	\omega,\theta}(a|G,q)=\sum_R P_\omega(a|G,q,R)*P_\theta(R|q)\\
> =E_{P_\theta(R,q)}[P_\omega(a|G,q,R)]
> $$
> 输入一个问题，对于每个可能的输出结果，找到二者之间的所有路径，计算路径概率之和。

### 4.2模块综述

> 规则挖掘模块对给定的query所产生的,每一个可能的R，给出一个先验概率
> $$
> P_\theta
> $$
> 推理验证模块将可能的规则R带入到图谱中，计算得出后验概率
> $$
> P_\omega
> $$
> 两个模块共同训练，目标函数为最大化样本的可能性：
> $$
> max_{\{\omega,\theta\}}Object=E_{(G,q,a)\sim P_d}[log{P_\omega(a|G,q)}]
> $$

### 4.3推理验证模块算法

该模块使用下述概率公式表示推理出的逻辑规则，构建马尔科夫逻辑网，然后在候选R集合上预测概率最高的答案
$$
P_{	\omega}(a|G,q,R)
$$
具体而言，对于每个输入q=(h,r,?)，可以在候选R集合上找到多组集合，每组集合得出候选答案a，构成集合A。每个答案的得分(w)为路径上关系的分数的和
$$
Score_\omega(a)=\sum_{rule\in R}\omega_{rule}
$$
然后对得分使用softmax函数，就得到我们需要的预测概率了
$$
P_{	\omega}(a=t|G,q,R)=\frac{exp(Score_{\omega}(a))}{\sum_{a'\in A} exp(Score_{\omega}(a'))}
$$
高预测概率的a作为候选答案，结合先验概率，计算得出这条规则的得分H，高得分的规则R送到规则挖掘模块。
$$
H(rule)=Score_{\omega}(t|rule)+logGRU_{\theta}(rule|q)\\
P(rule)=\frac{exp(H(rule))}{\sum_{rule'\in R} exp(H(rule'))}
$$

### 4.4规则挖掘模块算法

对于输入的q(h，r，？)，将他转化成关系的序列
$$
[r_q,r_i,...,r_e]\\\\
rq是查询语句中的关系，re是到达answer的最后一个关系，ri是推理过程中的reasoning logic rules
$$
基于GRU网络，该模块产生/选择一组逻辑规则，用于推理答案a。

用于生成潜在规则的，候选规则集合R的概率分布符合多项式分布：
$$
P_{\theta}(R|q)=MD(R|N,GRU_\theta(q))\\\\
N\quad represents\quad the\quad size\quad of\quad the\quad set\quad R, \\\\and \quad GRU_\theta(q) stands \quad for\quad the\quad distribution\quad over\quad rules\quad for\quad query\quad q
$$
分布是对应查询语句所涉及的R的分布。

GRU网络会生成大小为N的候选集R，GRU网络的结构如下
$$
h_0=f_1(v_r)\\
hi=GRU(h_{i-1},f_2([v_r,v_{ri}]))
$$

- h0：初始状态的隐层
- hi：第i个状态下的隐层
- f1，f2是线性变换函数
- vr是查询输入的关系r_head对应的embedding 向量，vri是规则上第i个关系r对应的embedding向量

首先通过线性变换函数f3，将hi+1映射到|R|维空间上，然后使用softmax函数，对映射过来的关系代表的向量进行概率归一化，得到下一个状态hi+1
$$
softmax(f3(h_{i+1}))
$$
最后，该模块输出K个高质量规则，用作训练集，进行参数优化
$$
max_{\theta}Object(\theta)=\sum_{rule\in R_k}logGRU_\theta(rule|q)
$$

## 5.Experments

> 测试数据集：小数据集KINSHIP（家庭关系），UMIS（生物医学）和大数据集WN18RR （WordNet的子数据集）and FB15K-237（Freebase subset FB15K的subset）

| Dataset   | Entities | Relations | Triples | Mean degree |
| --------- | -------- | --------- | ------- | ----------- |
| KINSHIP   | 104      | 25        | 8544    | 85.15       |
| UMLS      | 135      | 46        | 5216    | 38.63       |
| WN18RR    | 40945    | 11        | 86835   | 2.19        |
| FB15K-237 | 14505    | 237       | 272115  | 19.74       |



### 测试标准

选取代表性的评估矩阵（对每项指标赋予不同权重，表达不同侧重点）HITS@N和Mean Reciprocal Rank (MRR).

- HITS@N的计算公式：
  $$
  HITS@N=\frac{1}{|S|}\sum_{i=1}^{|S|}I(rank_i<=N)
  $$
  S：三元组集合，这个标准选择排名靠前的三元组占总三元组数量的比例作为评估标准。

- MRR的计算公式
  $$
  MRR=\frac{1}{|S|}\sum_{i=1}^{|S|}\frac{1}{rank_i}
  $$
  第一个匹配的结果得分为1，后面的得分为1/n

### 性能评估的标准化方法（Benchmark methods）

分为基于嵌入的方法，基于规则的逻辑的方法，基于强化学习的方法

> 基于嵌入的方法依赖于创建单词或概念的**高维表示**，然后可以使用这些高维表示来执行各种任务，例如分类或预测。这些方法通常涉及训练神经网络以将单词映射到其对应的嵌入维，以实现统一计算。包括DistMult,ComplEx, and ConvE. ConvE and ComplEx utilize the method proposed by Dettmers。
>
> 基于规则的逻辑方法包括创建一组规则或逻辑语句，用于做出决策或执行任务。这些方法通常包括创建一组规则，这些规则可以应用于给定的情况，以确定适当的行动方案。包括NLP and DRUM。
>
> 基于强化学习的方法包括训练智能体根据来自其环境的反馈做出决策。这些方法通常包括创建奖励函数，该函数基于代理的动作向代理提供反馈，并使用该反馈随着时间的推移调整代理的行为。包括MINERVA。



| Dataset   | Metric  | ComplEx | DistMult | ConvE | NeuralLP | DRUM  | MINERVA | GRULR |
| --------- | ------- | ------- | -------- | ----- | -------- | ----- | ------- | ----- |
| KINSHIP   | HITS@1  | 0.754   | 0.808    | 0.697 | 0.475    | 0.183 | 0.605   | 0.568 |
|           | HITS@3  | 0.91    | 0.942    | 0.886 | 0.707    | 0.378 | 0.812   | 0.824 |
|           | HITS@10 | 0.98    | 0.979    | 0.974 | 0.912    | 0.675 | 0.924   | 0.912 |
|           | MRR     | 0.838   | 0.878    | 0.797 | 0.619    | 0.335 | 0.72    | 0.715 |
| UMLS      | HITS@1  | 0.823   | 0.916    | 0.894 | 0.643    | 0.358 | 0.728   | 0.73  |
|           | HITS@3  | 0.962   | 0.967    | 0.964 | 0.869    | 0.699 | 0.9     | 0.893 |
|           | HITS@10 | 0.995   | 0.992    | 0.992 | 0.962    | 0.854 | 0.968   | 0.963 |
|           | MRR     | 0.894   | 0.944    | 0.933 | 0.778    | 0.548 | 0.825   | 0.814 |
| WN18RR    | HITS@1  | 0.41    | 0.39     | 0.4   | 0.368    | 0.369 | 0.413   | 0.412 |
|           | HITS@3  | 0.46    | 0.44     | 0.44  | 0.386    | 0.388 | 0.456   | 0.471 |
|           | HITS@10 | 0.51    | 0.49     | 0.52  | 0.408    | 0.41  | 0.513   | 0.522 |
|           | MRR     | 0.44    | 0.43     | 0.43  | 0.381    | 0.382 | 0.448   | 0.45  |
| FB15K-237 | HITS@1  | 0.158   | 0.155    | 0.237 | 0.173    | 0.174 | 0.217   | 0.245 |
|           | HITS@3  | 0.275   | 0.263    | 0.356 | 0.259    | 0.261 | 0.329   | 0.36  |
|           | HITS@10 | 0.428   | 0.419    | 0.501 | 0.361    | 0.364 | 0.456   | 0.497 |
|           | MRR     | 0.247   | 0.241    | 0.325 | 0.237    | 0.238 | 0.293   | 0.329 |

> 大数据集WN18RR和FB15K-237上，所有推理能力并且精度显著下降，例如基于嵌入方法（ComplEx、DistMult和ConvE）MRR指标下降了50%以上。
>
> 两种测试矩阵的表现比其他测试方法更好。
>
> GRULR在大数据集上比其他六种方法效果更好，因为GRULR可以联合优化规则挖掘模块和推理评估器模块，以生成用于KG推理的高质量逻辑规则。
>
> 基于嵌入的测试方法比测试矩阵方法表现更好，因为这些数据集本身不是用来进行逻辑推理规则的学习的。（logic reasoning）

![image-20230512190817160](C:\Users\8208191402\Desktop\笔记\图片\image-20230512190817160.png)

> 在使用GRULR, DRUM, and ComplEx三种模型比较时，随着数据量增多，GRULR准确率更高，因为规则是满足高质量要求的。

![image-20230512191052992](C:\Users\8208191402\Desktop\笔记\图片\image-20230512191052992.png)

> 推理规则是可以被人类理解的，if actor X was born in the U state and the U state belongs to the country Y, it
> is easy to get the nationality of actor X as Y. As shown in Table4, the logical inference is represented by symbols:
> $$
> ActorNationality(X, Y) \leftarrow BornIn(X, U) \and StateContain^{-1}(U, Y).
> $$

