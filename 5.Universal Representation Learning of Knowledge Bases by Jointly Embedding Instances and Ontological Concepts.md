# Universal Representation Learning of Knowledge Bases by Jointly Embedding Instances and Ontological Concepts

## 0.之前的学习

大规模知识库包括两层：本体层和实体层。本体层包含抽象的、常识性的概念，实体层包含根据具体的属性实例化的本体实例。目前的知识图谱大多分为两种：

以实体视图为中心的知识图谱，关系体现在具体实体之间，例如<“Biden”, “isPoliticianOf ”, “United States”>,

另一种是以本体试图为中心的知识图谱，只包含体现本体之间关系的语义元关系（meta-relation），例如<president, “isleaderOf ”, “country”>。知识图谱也提供跨视图的联系，用于确认一个实体是否是某个特定本体下的实例。知识图谱视图融合，可以通过把实体映射到低维向量空间，然后进行关系表示，从而挖掘实体和本体间的潜在语义关系，进而支持关系推理。

目前的研究大多停留在某一单独层面上，很少有实体和本体层之间的关系推理。对知识图谱进行跨层推理（cross-view）。本模型将二者结合，一方面可以利用实体层大量的数据为对应的本体提供更将详细的描述，并为推理结果提供更加可信的证明，例如对多个独立的音乐家进行观察，可以很容易的提取共同点“音乐”，从而为音乐家本体和音乐本体建立联系；另一方面本体对实体的高度概括可以对新加入图谱的实体进行合情推理，从而实现稀少样本实例的正确聚类。这一点对于实例数极少的本体很有效。例如，某个音乐家作品稀少，在实体层之和很少的音乐建立联系，但根据本体层的标记，他应该和其他音乐家的距离不会太远。

跨层视图的联系可以更好地发掘知识图谱中本体之间的关系，但是也会面临新的挑战。首先，关系的增多需要更多的实例和更大的词库，来建立、存储可信的关系。其次，实体层和本体层之间存在很多形式上没有关联（disjoint），语义上相关的关系，这些关系都**没有先例**，需要额外指定检验策略和阈值。实体层和本体层数量的巨大差距，也要求我们对概率进行正则化处理，避免不均衡样本带来的错误判断。

本模型实现了在本体和实体两个层面的映射方法，逻辑如下图所示。对于跨层视图之间的映射，设计单独的映射模型进行映射。对于视图内的映射，因为实体和本体层的实例数存在数量级上的区别，因此映射到两个不同的向量空间上。对于实体和本体数量差别不大的关系挖掘，使用grouping技术，将二者映射到同一个空间；对于实体和本体数量差别很大的关系挖掘，采用transformation[21]技术，对实体进行非线性转换，确保与主体对齐，同时保留原主体之间的等级关系。

近期有研究把知识图谱映射模型分为两类：基于嵌入的模型（将实体和关系映射到一个低维向量空间中，然后通过向量运算来推导实体之间的关系）和基于相似度的模型。代表性的嵌入模型包括TransE，将关系转化成映射向量r，采用如下的得分函数来衡量三元组的合理性：
$$
f(h,r,t)=||h+r-t||_2\\
distance(h,r,t)=f(h,r,t)-f(h',r,t)
$$
距离公式，是正样本和负样本之间的距离，也是该模型的损失函数。通过最小化正样本（合理的三元组）的得分和负样本（不合理的三元组）的得分之间的差距，可以训练出更好的实体和关系的向量表示，从而提高模型的预测精度。 

![img](file:///C:/Users/820819~1/AppData/Local/Temp/msohtmlclip1/01/clip_image004.png)

图2.1 JOIE构建流程

其他的Trans函数根据调整距离的计算方式来适应不同的需求，可以用于输入知识图谱的三元组补全。基于相似度的模型DisMult模型使用Hadamard积来表示不对称关系的映射的相似度，并运用于知识图谱补全。

## 1.Introduction

### 1.1背景介绍

目前的知识库包含很多内部统一表示的，多关系数据。实例视图的图谱包含具体实例之间的关系，本体视图的图谱包含抽象语义之间的元关系（semantic meta-relation）。图谱本身也包含跨视图的关系，用于连接本体和他实例化的实体。

![image-20230513083927292](https://cdn.jsdelivr.net/gh/pengcheng666236/picGo@master/image-20230513083927292.png)

目前，常用知识图谱嵌入（Knowledge Graph Embedding）模型去实现很多图谱的应用，包括智能问答关系抽取等，这是一类基于深度学习的方法，用于将知识图谱中的实体和关系映射到低维向量空间中，从而

- 捕捉实体和关系之间的潜在语义关系。
- 以向量代数的形式，支持关系推理

### 1.2模型介绍

大型知识库常包含两种视图：本体层面的，表达抽象和公认概念的视图（ABox），实例层面的，表达对本体实例化的具体实例的视图（TBox）。

本文提出一种联合两种视图的KG embedding技术：JOIE。

- JOIE包含cross-view和intra-view模型，从多个层面学习知识库的数据。
  - 跨视图模型通过在实例的embedding向量，和它对应的本体embedding向量之间建立联系，来学习。
  - 视图内模型通过在视图内部捕获结构化数据来进行训练，其中还包含一个本体层（ontology）的层次感知编码技术（hierarchy-aware encoding technique），用于支持存在层级关系的本体。

本模型通过在大数据集上，通过少量跨层链接，对实体和本体进行统一学习，主要包含

- 两个视图内部的关系
- 视图之间的链接

将知识库的两个视图上的表示学习技术有效地结合在一起，它面临着以下挑战

- 很多实体、本体、关系、元关系的词汇形式上完全不同，但有隐含的语义关联
- 目前没有有效的embedding技术，能够准确描述从本体、元关系到实体和关系的语义映射（semantic mapping）
- 跨视图连接的数量，不足以覆盖庞大的实体空间，从而难以做到两个视图的实体对齐和统一表示，进而限制了对新跨视图链接的挖掘
- 两种视图的规模和拓扑结构完全不同，
  - 本体视图是稀疏的，关系种类少，会形成层次级别的子结构
  - 实体视图实例和关系数量多

该技术包含两个模块：

- cross-view association model，把实体层的例子的embedding和对应的本体的embedding进行关联，使用两种技术来获取跨层链接
  - cross-view grouping technique，假设两个视图可以被强迫性的映射到同一个向量空间
  - cross-view transformation technique，通过非线性变换函数，将实例的embedding空间映射到本体的embedding空间，同时赋予实例本体之间的等级关系。
- intra-view embedding model，把本体和实体视图内的关系事实（relation fact）特征化为两个独立的embedding空间，使用三种基于translational变换，或者基于相似度的关系映射（relation embedding）工具，来获取两种视图内的多关系结构（例如transH，将实体和关系映射到两个不同的向量空间）
- 对于图谱本体层的等级关系结构，使用hierarchy-aware embedding technique，该技术层内的非线性映射函数，在映射的时候保留这种层级关系/子结构 。

对本模型的九种变体的三种，分别进行三元组补全任务，和实例分类预测任务。

## 2.Related Work

### KG embedding

目前很多工作都是基于实例层的embedding，给定三元组（h，r，t），r表示头实体和尾实体之间的关系，重点是找到一个合理的得分函数f，作为模型优化的目标函数。
$$
f_r( \textbf{h},\textbf{t})\\
\textbf{h},\textbf{t}\quad are \quad the \quad embedding \quad of \quad h,t
$$
目前，KG embedding model主要分为

- 基于变换的translationX模型（例如上文提到的TransE，将关系转化为两个实体embedding向量之间的距离，后续的trans模型通过改变translation函数，映射到不同的、关系特定的空间上）
- 基于相似度的模型，DisMult模型通过两个embedding向量的哈德曼积（向量内积），来关联相关的实体；HolE模型使用循环相关函数来计算关系（计算两个周期性信号之间相似度的方法，它可以将两个信号在正向和反向方向上进行匹配，从而得到一个循环相似度），提高对不对称关系的encoding效率；ComplEx将DisMult模型映射到更复杂的空间来提高效率。

上述方法虽然计算了实体类型（entity type）的相似度，但没有捕获不同实体类型之间的语义关系；而且这些方法没有把实例推理出的关系运用到本体扩容或者建立本体与实体的联系上。

### Multi-graph Embeddings for KGs

目前有研究，把嵌入模型运用到连接多个不同结构的KG领域，用来弥补单个知识图谱的缺陷。

典型方法就是多语言学习（这里的语言是不同维度的embedding向量），例如MTransE，通过在已经转换过的两个不同的embedding place上，学习一种统一的embedding translation方法，从而实现不同图谱的融合，巧的是，我们把一个图谱分为两个视图来看，相当于是两个图谱，也可以用这种方法。

问题是，这种方法依赖于这几个图谱的拓扑结构相似，而我们的两个视图肯定不满足要求。该模型的衍生方法（KDCoE and JAPE），在给定额外的文本描述+图谱的数字特征（实体数量等等）之后，可以使用，而我们的视图缺乏这些数据。

总而言之，目前的方法不符合我们的预料库和任务需求。

### Ontology Population（本体填充）

> 自动从
>
> - 非结构化或半结构化数据源（例如文本文档或数据库）中
> - 现有本体中
>
> 识别新概念和关系，并将它们添加到本体中。

传统的方法依靠大量人工标注的语料，从而挖掘元关系事实（meta-relation fact）。

有的研究，把embedding技术扩展到跨领域知识图谱（ConceptNet）的数据融合上，典型的有On2Vec：把传统的embedd扩展，从而获取关系的属性值和本体的等级关系，这证明了embedding对关系推理有作用，本文将该模型从本体扩展到实体层面。

## 3.Modeling

由cross-view association model和intra-view model组成，本部分从知识库的形式化表示开始

![image-20230513153332637](https://cdn.jsdelivr.net/gh/pengcheng666236/picGo@master/image-20230513153332637.png)

### 3.1Formalization of two-view knowledge base

在知识库，分别使用Gi和Go表示实体视图和本体视图,每个视图对应一个独立的embedding向量空间，用于映射视图内的点和边。
$$
G_i= 	\{ \varepsilon,R_I\}=set{(\mathbf h^{(I)},\mathbf r^{(I)}，\mathbf t^{(I)})}\\
G_o= 	\{ C,R_O\}=set{(\mathbf h^{(O)},\mathbf r^{(O)}，\mathbf t^{(O)})}\\
\varepsilon是entities集合，R_I是关系集合\\
\varepsilon和C，R_I和R_O是是不相交的两个集合\\\\
S=set(e,o)\\用于表示跨层关系的集合，例如type\_of\\\\
\Gamma =set(C_l,C_h)\\
用于表示本体层的等级关系(这种等级关系本身也是一种元关系)，例如subclass\_of
$$
模型的目的：通过建立cross-view association model和intra-view model模型，能够从两个视图中学习能够统一表示的embedding方法。

- cross-view association model通过对本体对应实例的捕获，实现视图之间的连接以及信息流。
- intra-view model在每个视图上对本视图的本体和实体进行encode映射

### 3.2 cross-view association model

该模块的任务是寻找两个视图不同embedding空间之间的关系，主要基于两视图之间原本存在的链接。如前言所述，分为Cross-view Grouping (CG) 和 Cross-view Transformation(CT)两种工具，二者基于不同的假设，进而拥有不同的优化目标函数。

#### 3.2.1 Cross-view Grouping

一种基于分组（grouping）的正则化方法（regularization）。假设两个视图可以被强行映射到同一个embedding空间（dimension(concept)=dimension(entity)=d），同时强行要求所有entities靠近所对应的concept。![image-20230513162927087](C:\Users\8208191402\Desktop\笔记\图片\image-20230513162927087-16839667757994.png)

CG模型的损失函数用c和e二者的距离的绝对值表示：
$$
J^{CG}_{Cross}=\frac{1}{|S|}\sum_{(e,c)\in S}[||c-e||_2- \gamma^{CG}]_+\\
\gamma^{CG}是损失函数的margin\\
$$

- Margin是指在损失函数中的一个可变的加在loss上的一个偏移量，它可以手动调节偏移。
- 在机器学习中，Margin也有类似的意思，它可以理解为一个距离的概念，表示正负样本之间的距离。
- 在一些损失函数中，如Hinge Loss和MarginRankingLoss，Margin被用来表示正负样本之间的距离，即正样本和负样本之间的最小距离。
- 通过调整Margin的大小，可以**控制正负样本之间的距离**，**决定聚类的拥簇程度**，从而影响模型的性能。

[]+表示函数f=max(x,0),用于惩罚某些entity的嵌入向量，这些entities落在以对应concept的嵌入向量为中心的半径邻域之外，margin对聚类程度有很大的决定作用。

#### 3.2.2 Cross-view Transformation(CT)

寻找第二层embedding，把两个视图各自的embedding向量再进行一次向Concept向量空间进行统一。

![image-20230513163142655](C:\Users\8208191402\Desktop\笔记\图片\image-20230513163142655.png)

实例会被映射到本体空间，同时与对应本体的位置接近：
$$
\mathbf c \leftarrow f_{CT}(\mathbf e),\forall(e,c)\in S\\
f_{CT}=\sigma (\mathbf W_{CT} \bullet \mathbf e+\mathbf b_{CT})\\
f_{CT}是一个非线性函数,本文使用tanh。\\
\mathbf W_{CT}是(d2,d1)维的权重矩阵，\mathbf b是偏移
$$
CT模型的损失函数用正例符合，负例不符合的映射之和表示
$$
J^{CT}_{Cross}=\frac{1}{|S|}\sum_{(e,c)\in S \and (e,c')\in S}[\gamma^{CT}+||c-f_{CT}(\mathbf e)||_2- ||c'-f_{CT}(\mathbf e)||_2]_+\\
$$


### 3.3 Intra-view Model

该模型的目的是：保存视图内部的结构化数据。

因为这个问题分散在两个视图上，可以使用两套独立方案解决，提高了下游任务的效率。在本节中，我们提供两种视图内的，用于不同图结构编码的模型技术。

#### 3.3.1 Default Model

通常，把一个三元组映射到图谱中，需要一个得分函数来判断映射的合理性。我们选择三个传统的三元组嵌入工具：TransE，Multiplication，circular correction并分别计算得分函数：
$$
f_{transE}(\mathbf {h,r,t})=-||\mathbf {h+r-t}||_2\\
f_{transE}(\mathbf {h,r,t})=\mathbf {(h\bigcirc r)	\cdot t}\\
f_{transE}(\mathbf {h,r,t})=\mathbf {(h\bigstar r)	\cdot t}\\
\bigcirc = Hadamard \quad product,矩阵对应位置元素相乘,c_{ij}=a_{ij}*b_{ij}\\
\bigstar=circular\quad correlation,循环相关函数,[a\bigstar b]_k=\sum_{i=0}^da_ib_{(k+i) mod \quad d}
$$
*the circular correlation at a given shift k is the sum of the element-wise products of the two sequences, where one sequence is circularly shifted by k positions.*

下面是损失函数，介绍一下hinge loss公式的背景：
$$
L(y, f(x)) = max(0, 1 - y*f(x))
$$
为了学习：三元组embedding向量，转化到图谱节点的embedding向量，对图谱所有节点（nodes）求一个总体最小的hinge loss值：
$$
J_{Intra}^G=\frac{1}{|G|}\sum_{(h,r,t)\in G \and (h',r,t') \notin G}[\gamma^G+f(h',r,t')-f(h,r,t)]_+\\
\gamma^{G}是一个正的边界\\
(h',r,t') 指的是一个被修改过的三元组，该三元组更改了头结点或尾节点，从而不存在于图谱中。\\
J表示总体损失函数
$$
> 三元组是知识图谱中最基本的数据单元，由主体、谓词和客体组成。
>
> 如果三元组中的任何一个元素被错误地修改、删除或替换，那么这个三元组就被称为"corrupted triples"。
>
> 这可能是由于数据输入错误、数据清理不完全或恶意攻击等原因导致的。
>
> 在知识图谱的应用中，发现和修复corrupted triples是非常重要的，因为这能够确保知识图谱中的数据的准确性和可靠性。

上述嵌入工具和损失函数在本体视图和实体视图都是适用的，对两层分别计算，加权求和
$$
J_{Intra}^G=J_{Intra}^{G_I}+\alpha_1 * J_{Intra}^{G_O}\\
\alpha_{1}是超参数，用于表示本体层和实体层的结构差别
$$
使用同一种方式衡量两个视图的目的：强制执行某个范例在两个视图中的关系推理作用。

#### 3.3.2 Hierarchy-Aware Intra-view Model for the Ontology

本体层常常会包含一些等级关系，这些关系往往会体现在某个元关系的等级性属性上（subclass of，is a等等）。该模型的任务，就是把可能表示等级关系的元关系，和普通的语义元关系（related to等等）区分开。

具体的，我们使用和3.2.2跨视图映射相似的方法，对<关系1-层次关系-关系2>使用非线性映射：
$$
(c_{lower},c_{higher})\\
g_{HA}(c_h)=\sigma(\mathbf W_{HA}\cdot c_l+\mathbf b_{HA})\\
\mathbf W_{HA}是d2 \cdot d2的矩阵，\mathbf b_{HA}是偏移\\
\sigma(\cdot)=tanh(\cdot)
$$
根据上述公式，得出关于等级关系实体的损失函数：
$$
J_{Intra}^{HA}=\frac{1}{|\gamma|}\sum_{(c_l,c_h)\in \gamma \and (c_l,c_{h'})\notin \gamma}[\gamma_{HA}+||c_h-g(c_l)||_2-||c_{h'}-g(c_l)||_2]_+
$$
从而，具有等级关系的模型的损失函数为：
$$
J_{Intra}^G=J_{Intra}^{G_I}+\alpha_1 * J_{Intra}^{G_O}+\alpha_2 * J_{Intra}^{HA}
$$
前两项仅使用普通语义关系进行训练，第三项使用具有等级关系的语义关系进行训练。

### 3.4 Joint Training on Two-View KBs

$$
J=J_{Intra}+\omega \cdot J_{Cross}\\
参数优化按照从内向外的顺序，J_{Intra}^{G_I},J_{Intra}^{G_O},J_{Cross}的顺序\\
\theta^{new} \leftarrow \theta^{old}-\eta \cdot \nabla J_{Intra}\\
\theta^{new} \leftarrow \theta^{old}-(\omega \eta) \cdot \nabla J_{Cross}\\
$$

- 将网络初始权重随即化为正交矩阵，即random orthogonal initialization 方法
- 使用AMSGrad optimizer来优化联合损失函数
  - AMSGrad optimizer是一种优化器，是Adam optimizer的一种变体。Adam optimizer是一种常用的优化器，用于训练神经网络模型。
- 训练时
  - 强制让所有实体和本体的表示向量，的L2范数归一化，防止有的向量会因为数值过小而归零。
  - 在视图内和视图间模型都使用负样本，正负样本1:1
  - 两个模型的所有变量，都用hinge loss函数作为损失函数

### 3.5 JOIE的变量和复杂度

共有六种变体，即组合3.2的两种和3.3的三种，例如“JOIE-TransE-CT”表示cross-view使用 Transformation，Intra view使用TransE为基础的default model。

此外，对于使用CT表示的跨层视图关系，可以将跨层translation运用到等级关系上，额外添加三种模型JOIE-HA TransE-CT, JOIE-HA Mult-CT, and JOIE-HA HolE-CT.

复杂度计算

> 分别用ne，nc，nr，nm表示实体，概念本体，关系，元关系的总数（ne>>nc），de，dc分别表示本体和实体的维度（Grouping中二者相等）
>
> 模型复杂度：
> $$
> CG-based:n_ed_e+n_cd_c\\
> CT-based:n_ed_e+n_cd_c+d_ed_c\\
> 对于使用等级关系的，还要加上d_c^2
> $$
> 因为实体远多于本体，所以复杂度主要取决于实体数量，即训练代价和图谱三元组数量成正比。
>
> 对于三元组补全工作，时间复杂度等于
> $$
> O(n_ed_e ) for\quad the\quad instance-view\quad graph \quad or \\
> O(n_cd_c ) for\quad the\quad ontology-view\quad graph.
> $$
> 对于实体识别工作，时间复杂度等于
> $$
> O(n_cd_e ) for\quad CG\quad or \quad O(n_cd_cd_c ) for\quad CT
> $$
> 因为CT要先做一次映射。

### 4.Experments

数据集：YAGO26K-906 和 DB111K-174。这两个数据集的关系密度不同：DB111K包含更多的从entity到concept的关系映射。[下载地址]:https://github.com/JunhengH/joie-kdd19.

|             | Instance | Graph     | GI      | Ontology | Graph          | GO      |             |
| ----------- | -------- | --------- | ------- | -------- | -------------- | ------- | ----------- |
| Dataset     | entities | relations | triples | concepts | meta-relations | triples | type-link S |
| YAGO26K-906 | 26,078   | 34        | 390,738 | 906      | 30             | 8,962   | 9,962       |
| DB111K-174  | 111,762  | 305       | 863,643 | 174      | 20             | 763     | 99,748      |

#### 4.2 KG Completion

三元组补全的任务是，构建图谱中缺失的关系事实，这些关系是用来衡量学习到的embedding 质量的，为什么这些关系可以衡量词嵌入的质量：

- 嵌入向量的相似度：对于知识图谱中的两个实体，如果它们之间的关系被学习到了，那么它们在嵌入空间中的向量应该相似。因此，可以通过计算它们的**向量相似度**，来衡量嵌入向量的质量。向量相似度（h+r和t）越大，说明嵌入空间质量越好。
- 关系预测准确率：对于知识图谱中的某个关系，如果学习到的**嵌入向量能够准确地预测该关系的存在或缺失**，那么可以认为该嵌入向量的质量较高。
- 关系分类准确率：对于知识图谱中的某个关系，如果学习到的**嵌入向量能够将该关系正确地分类**到相应的关系类型中，那么可以认为该嵌入向量的质量较高。

> 在TransE模型中，**平移是一种非线性变换**，因为它是通过将实体向量平移一定距离得到另一个实体向量的。与线性变换不同，平移不满足加法和数乘的封闭性，因此不能用线性代数的方法来描述。在TransE模型中，平移被建模为**向量的加法，但这种加法是非线性的**，因为它不满足加法的封闭性。因此，平移不能被看作是线性变换。

本模块把任务分成Instance-view KG completion和ontology population。

##### Evaluation Protocol

首先，参照目前常用的实例层embedding模型，把所有ontology 和Instance triples分为85%训练集，5%验证集，10%测试集。然后，基于训练集GI和GO，以及所有的跨层关系集合S，训练模型。接着，根据测试输入query（h，r，t？），计算出概率函数f，然后由每个视图内部进行计算和排名（rank）。

测试函数使用三种正测试指标（metric不是matrix）：mean reciprocal ranks (MRR), accuracy (Hits@1) and the proportion of correct answers ranked within the top 10 (Hits@10)。同时，采用过滤指标（采用了过滤度量来评估知识图谱补全模型的性能，这些度量假定候选空间已经排除了在训练集中出现过的三元组，以避免测试集和训练集之间的数据泄漏问题）

|      | dimension entity | dimension concept | learning rate         | a1   | a2   |
| ---- | ---------------- | ----------------- | --------------------- | ---- | ---- |
| CT   | 300              | 50                | {0.0005, 0.001, 0.01} | -    | -    |
| CG   | 200              | 200               | {0.0005, 0.001, 0.01} | 2.5  | 10.  |

|        | margin I | margin O |
| ------ | -------- | -------- |
| transE | 0.5      | 0.5      |
| Multi  | 1        | 1        |

epoch120

##### Baselines

"baseline"通常被翻译为“基准线”、“基准模型”或“基础模型”，指的是在比较不同模型、算法或方法时，作为比较的标准或基础的模型或方法。

这里选择3个baseline方法：TransE, DistMult，HolE 

- 1.先只在一个视图上进行训练，结果显示为base
- 2.同时使用GI和GO上的训练集，同时纳入一种跨层关系type_of，结果显示为all

TransC方法（不适用于ontology completion）

- 同时使用两个视图上的训练数据来训练
- 和TransE的区别在于对本体到实例的映射函数不同
- TransC是一个不包含语义元关系的、简化的JOIE-TransE-CG模型

##### Results

![image-20230515160749185](https://cdn.jsdelivr.net/gh/pengcheng666236/picGo@master/image-20230515160749185.png)

- JOIE能更好的利用本体层信息，来在本体层执行三元组补充任务。

- 因为图的稀疏性，基于嵌入的TransE比基于相似度的方法更加不容易受稀疏图的影响。

- 加入等级感知技术（HA）后，实例层的关系补全效果显著提高，尤其是在Trans变种和循环相关函数模型上。

#### 4.3 Entity Typing

给定一组实例，预测所对应的本体是谁。和三元组完善任务一样，对所有候选进行排序，选择rank最高的进行评估计算。

##### Evaluation Protocol

对跨层关系S，划分60%训练集和和40%测试集。超参数从三元组补全任务中继承，因为是同一个数据集。测试流程：

- 给定特定实体的query，转化成嵌入向量query（eq=h，r，t？）
- 对将eq进行映射，从实体空间投影到图谱本体空间后，根据嵌入向量的距离得出的候选实体，计算排名
- 然后计算误差：MRR, Hit@1 (i.e. accuracy) and Hit@3

##### Baselines

四个模型：TransE, DistMult, HolE and MTransE

- 对前三种模型，把跨层的链接转化为三元组：

  - 

  $$
  (e,c)\rightarrow(e,t,c)\\
  t:is\_type\_of
  $$

  这样实体识别任务就转化成基于上述模型的三元组补全任务了。666

- 对MTransE模型（多关系），本体和实体视为两个独立视图，即视为两个不同语言表示的知识库，使用基于距离的ranking

##### Result

![image-20230515170023110](https://cdn.jsdelivr.net/gh/pengcheng666236/picGo@master/image-20230515170023110.png)

早就预见到CT模型会比CG更好，这里解释原因：

- CT允许两个向量映射空间拥有不同的维度，更好的描述本体空间数据稀少，规模小的特征
- 两个视图的拓扑结构可能存在不一致
